{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center><font size = \"6\">How to Choose a Feature Selection Method For Machine Learning<center>**\n",
    "***\n",
    "<center><font size = \"2\">Prepared by: Sitsawek Sukorn<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is the process of reducing the number of input variables when developing a predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Statistical-based feature selection method --> evaluating the relationship between each input and target variable.\n",
    "- Strongest relationship between input and output variable.\n",
    "- Depends on data type of both input and output variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsupervised**\n",
    "- Do not use the target variable (e.g. remove redundant variables). --> correlation\n",
    "\n",
    "**Supervised**\n",
    "- Use the target variable (e.g. remove irrelevant variables).\n",
    "\n",
    "*Wrapper* : Search for well-performing subsets of features. --> RFE\n",
    "\n",
    "*Filter* : Select subsets of features based on their relationship with target. --> Statistical Methods, Feature Importance Methods\n",
    "\n",
    "*Intrinsic* : Algorithms that perform automatic feature selection during training. --> Decission Trees\n",
    "\n",
    "**Dimensionality Reduction**\n",
    "- Project input data into a lower-dimensional feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics for Filter-Based Feature Selection Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Common input variable data type**\n",
    "\n",
    "*Numerical Variables*\n",
    "- Interger Variables.\n",
    "- Floating Point Variables.\n",
    "\n",
    "--> output for regression predictive modeling problem.\n",
    "\n",
    "*Categorical Variables*\n",
    "- Booleans Variables (dichotomus).\n",
    "- Ordinal Variables.\n",
    "- Nominal Variables.\n",
    "\n",
    "--> output for classification predictive modeling problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to Choose a Feature Selection Method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Numerical input*\n",
    "- Numerical output --> Pearson's (linear), Spearman's (non-linear)\n",
    "- Categorical output --> ANOVA (linear), Kendall's (non-linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Categorical input*\n",
    "- Numerical output --> ANOVA (linear), Kendall's (non-linear)\n",
    "- Categorical output --> Chi-Squared, Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tip and Tricks for Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When using filter-based feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation Statistics**\n",
    "\n",
    "*scikit-learn* --> import sklearn.feature_selection\n",
    "- Pearson's Correlation Coefficient : f_regression()\n",
    "- ANOVA : f_classif()\n",
    "- Chi-Squared : chi2()\n",
    "- Mutual Information : mutual_info_classif() and mutual_info_regression()\n",
    "\n",
    "*SciPy* --> scipy.stats\n",
    "- Kendall's tau : kendalltau()\n",
    "- Spearman's rank correlation : spearmanr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selection Method**\n",
    "\n",
    "Two more popular methods include:\n",
    "- Select the top k variables: SelectKBest()\n",
    "- Select the top percentile variables: SelectPercentile()\n",
    "\n",
    "*machinelearningmastery often use SelectKBest()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform Variables**\n",
    "- Can transform a categorical variable to ordinal, even if it not, and see if any interesting results come out.\n",
    "- Can also make numerical variable discrete(e.g. bin); try categorical-based measures.\n",
    "- Some statistical measures assume properties of the variables, such as Pearson's that assumes a Gaussian probability distribution to the observations and a linear relationship. You can transform the data to meet the expectations of the test and try the test regardless of the expectations and compare results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the Best Method?**\n",
    "- You must discover what works best for your specific problem using careful systematic of experimentation.\n",
    "- Try a range of different models fit on different subsets of features chosen via different statistical measures and discover what works best for your specific problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
