{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center><font size = \"6\">How to Choose a Feature Selection Method For Machine Learning<center>**\n",
    "***\n",
    "<center><font size = \"2\">Prepared by: Sitsawek Sukorn<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is the process of reducing the number of input variables when developing a predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Statistical-based feature selection method --> evaluating the relationship between each input and target variable.\n",
    "- Strongest relationship between input and output variable.\n",
    "- Depends on data type of both input and output variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsupervised**\n",
    "- Do not use the target variable (e.g. remove redundant variables). --> correlation\n",
    "\n",
    "**Supervised**\n",
    "- Use the target variable (e.g. remove irrelevant variables).\n",
    "\n",
    "*Wrapper* : Search for well-performing subsets of features. --> RFE\n",
    "\n",
    "*Filter* : Select subsets of features based on their relationship with target. --> Statistical Methods, Feature Importance Methods\n",
    "\n",
    "*Intrinsic* : Algorithms that perform automatic feature selection during training. --> Decission Trees\n",
    "\n",
    "**Dimensionality Reduction**\n",
    "- Project input data into a lower-dimensional feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics for Filter-Based Feature Selection Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Common input variable data type**\n",
    "\n",
    "*Numerical Variables*\n",
    "- Interger Variables.\n",
    "- Floating Point Variables.\n",
    "\n",
    "--> output for regression predictive modeling problem.\n",
    "\n",
    "*Categorical Variables*\n",
    "- Booleans Variables (dichotomus).\n",
    "- Ordinal Variables.\n",
    "- Nominal Variables.\n",
    "\n",
    "--> output for classification predictive modeling problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to Choose a Feature Selection Method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Numerical input*\n",
    "- Numerical output --> Pearson's (linear), Spearman's (non-linear)\n",
    "- Categorical output --> ANOVA (linear), Kendall's (non-linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Categorical input*\n",
    "- Numerical output --> ANOVA (linear), Kendall's (non-linear)\n",
    "- Categorical output --> Chi-Squared, Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tip and Tricks for Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When using filter-based feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation Statistics**\n",
    "\n",
    "*scikit-learn* --> import sklearn.feature_selection\n",
    "- Pearson's Correlation Coefficient : f_regression()\n",
    "- ANOVA : f_classif()\n",
    "- Chi-Squared : chi2()\n",
    "- Mutual Information : mutual_info_classif() and mutual_info_regression()\n",
    "\n",
    "*SciPy* --> scipy.stats\n",
    "- Kendall's tau : kendalltau()\n",
    "- Spearman's rank correlation : spearmanr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selection Method**\n",
    "\n",
    "Two more popular methods include:\n",
    "- Select the top k variables: SelectKBest()\n",
    "- Select the top percentile variables: SelectPercentile()\n",
    "\n",
    "*machinelearningmastery often use SelectKBest()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform Variables**\n",
    "- Can transform a categorical variable to ordinal, even if it not, and see if any interesting results come out.\n",
    "- Can also make numerical variable discrete(e.g. bin); try categorical-based measures.\n",
    "- Some statistical measures assume properties of the variables, such as Pearson's that assumes a Gaussian probability distribution to the observations and a linear relationship. You can transform the data to meet the expectations of the test and try the test regardless of the expectations and compare results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the Best Method?**\n",
    "- You must discover what works best for your specific problem using careful systematic of experimentation.\n",
    "- Try a range of different models fit on different subsets of features chosen via different statistical measures and discover what works best for your specific problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Worked Examples of Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression Feature Selection: (Numerical Input, Numerical Output)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson's correlation feature selection for numeric input and numeric output\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import pandas as pd\n",
    "# Generate dataset\n",
    "X, y = make_regression(n_samples=100, n_features=100, n_informative=10)\n",
    "# Define feature selection\n",
    "fs = SelectKBest(score_func=f_regression, k=10)\n",
    "# Apply feature selection\n",
    "X_selected = fs.fit_transform(X, y)\n",
    "# print(X_selected.shape)\n",
    "a = pd.DataFrame(X)\n",
    "b = pd.DataFrame(y).rename(columns={0:'label'})\n",
    "c = pd.concat([a, b], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = SelectKBest(score_func=f_regression, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_choose = fs.fit_transform(c.iloc[:, :-1], c.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.247694</td>\n",
       "      <td>-0.387708</td>\n",
       "      <td>0.632681</td>\n",
       "      <td>-0.276245</td>\n",
       "      <td>-0.172128</td>\n",
       "      <td>-0.985949</td>\n",
       "      <td>0.889518</td>\n",
       "      <td>0.366668</td>\n",
       "      <td>-0.323041</td>\n",
       "      <td>0.040358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.531734</td>\n",
       "      <td>-0.955553</td>\n",
       "      <td>-0.840907</td>\n",
       "      <td>-1.294934</td>\n",
       "      <td>0.189587</td>\n",
       "      <td>-0.801920</td>\n",
       "      <td>-0.694504</td>\n",
       "      <td>-0.825560</td>\n",
       "      <td>-0.068377</td>\n",
       "      <td>1.150303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.464535</td>\n",
       "      <td>0.503714</td>\n",
       "      <td>-1.747163</td>\n",
       "      <td>-0.258527</td>\n",
       "      <td>0.448751</td>\n",
       "      <td>-0.154598</td>\n",
       "      <td>-0.513932</td>\n",
       "      <td>-0.632027</td>\n",
       "      <td>0.027348</td>\n",
       "      <td>-1.701479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.572872</td>\n",
       "      <td>1.621995</td>\n",
       "      <td>-0.821452</td>\n",
       "      <td>-1.655734</td>\n",
       "      <td>2.247372</td>\n",
       "      <td>-1.198173</td>\n",
       "      <td>-0.152114</td>\n",
       "      <td>-0.986263</td>\n",
       "      <td>-1.369093</td>\n",
       "      <td>0.600471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.089259</td>\n",
       "      <td>-1.611546</td>\n",
       "      <td>0.557194</td>\n",
       "      <td>1.323147</td>\n",
       "      <td>0.197278</td>\n",
       "      <td>-0.196250</td>\n",
       "      <td>0.725134</td>\n",
       "      <td>1.688488</td>\n",
       "      <td>-2.504461</td>\n",
       "      <td>-0.987967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \n",
       "95 -0.247694 -0.387708  0.632681 -0.276245 -0.172128 -0.985949  0.889518  \\\n",
       "96 -0.531734 -0.955553 -0.840907 -1.294934  0.189587 -0.801920 -0.694504   \n",
       "97 -0.464535  0.503714 -1.747163 -0.258527  0.448751 -0.154598 -0.513932   \n",
       "98  0.572872  1.621995 -0.821452 -1.655734  2.247372 -1.198173 -0.152114   \n",
       "99  1.089259 -1.611546  0.557194  1.323147  0.197278 -0.196250  0.725134   \n",
       "\n",
       "           7         8         9  \n",
       "95  0.366668 -0.323041  0.040358  \n",
       "96 -0.825560 -0.068377  1.150303  \n",
       "97 -0.632027  0.027348 -1.701479  \n",
       "98 -0.986263 -1.369093  0.600471  \n",
       "99  1.688488 -2.504461 -0.987967  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_choose).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Feature Selection: (Numerical Input, Categorical Output)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n"
     ]
    }
   ],
   "source": [
    "# ANOVA feature selection for numeric input and categorical output\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "X, y = make_classification(n_samples=100, n_features=20, n_informative=2)\n",
    "fs = SelectKBest(score_func=f_classif, k=3)\n",
    "X_selected = fs.fit_transform(X, y)\n",
    "print(X_selected.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Feature Selection: (Categorical Input, Categorical Output)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
